# LLM Python Application with Gradio Interface

## Overview
This project is a Python-based LLM (Large Language Model) application that uses Gradio for UI interactions. The app allows users to input a question and an additional prompt to guide the response, and the response is generated by calling a back-end model.

## Features
- Gradio-based UI with a question input box, prompt input box, and output box.
- Predefined prompt examples to assist users.
- Flexible model backend to support Qwen/Qwen2-VL-7B-Instruct.
- Customizable system prompt for controlling the assistant's behavior.

## Project Structure
```
project_name/
├── app.py          # Main application with Gradio UI
├── chatbot.py      # Chatbot logic for model interaction
├── README.md       # Documentation for the project
└── requirements.txt # Required Python packages
```

## How to Run
1. Install the required dependencies:

    ```sh
    pip install -r requirements.txt
    ```

2. Run the application:

    ```sh
    python app.py
    ```

## Dependencies
- gradio
- (Optional: Backend model dependencies such as Transformers or other libraries to interact with LLM models)

# requirements.txt
gradio

# Example for running the project
To run the project, first install dependencies and then launch the app:

```sh
pip install -r requirements.txt
python app.py